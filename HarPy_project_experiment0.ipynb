{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "comparative-baseline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8473\n",
      "2119\n",
      "8473\n",
      "2119\n"
     ]
    }
   ],
   "source": [
    "#### SETUP ####\n",
    "\n",
    "import csv\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "# READ IN THE TRAINING DATA\n",
    "\n",
    "X_txt = []\n",
    "y = []\n",
    "with open('./train.tsv') as in_file:\n",
    "    iCSV = csv.reader(in_file, delimiter='\\t')\n",
    "    for row in iCSV:\n",
    "        X_txt.append(row[1])\n",
    "        y.append(row[2])\n",
    "\n",
    "# SPLIT THE TRAINING DATA INTO TRAINING (80%) AND VALIDATION (20%) SUBSETS        \n",
    "\n",
    "X_txt_train, X_txt_val, y_train, y_val = train_test_split(X_txt, y, test_size=0.2, random_state=42)\n",
    "print(len(X_txt_train))\n",
    "print(len(X_txt_val))\n",
    "print(len(y_train))\n",
    "print(len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "general-realtor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOT    7069\n",
       "TIN    3102\n",
       "UNT     421\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the breakdown of the 3 classes in our training data?\n",
    "\n",
    "import pandas\n",
    "pandas.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "coated-petroleum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "[Parallel(n_jobs=1)]: Done 108 out of 108 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                                       ('clf', LinearSVC(random_state=42))]),\n",
       "             param_grid={'clf__C': [0.01, 0.1, 1.0], 'vec__min_df': [1, 5, 10],\n",
       "                         'vec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'vec__stop_words': ['english', None]},\n",
       "             scoring='f1_micro', verbose=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### TRAIN SOME BASELINE MODELS ####\n",
    "\n",
    "# LINEAR SVC\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vec', CountVectorizer()), \n",
    "    ('clf', LinearSVC(random_state=42))])\n",
    "\n",
    "params = {'vec__ngram_range':[(1,1),(1,2)],\n",
    "          'vec__stop_words':['english', None], \n",
    "          #'vec__lowercase':[False, True],\n",
    "          'vec__min_df':[1, 5, 10],\n",
    "          'clf__C':[0.01, 0.1, 1.]}\n",
    "clf = GridSearchCV(pipeline, params, scoring=\"f1_micro\", cv=3, verbose=1)\n",
    "clf.fit(X_txt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accepting-newark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LinearSVC Micro F1: 0.7324\n",
      "Best LinearSVC Parameters: {'clf__C': 0.1, 'vec__min_df': 1, 'vec__ngram_range': (1, 1), 'vec__stop_words': 'english'}\n",
      "Validation LinearSVC Micro F1: 0.7268\n",
      "Validation LinearSVC Macro F1: 0.4487\n"
     ]
    }
   ],
   "source": [
    "print(\"Best LinearSVC Micro F1: {:.4f}\".format(clf.best_score_))\n",
    "print(\"Best LinearSVC Parameters:\", clf.best_params_)\n",
    "\n",
    "preds = clf.predict(X_txt_val)\n",
    "print(\"Validation LinearSVC Micro F1: {:.4f}\".format(f1_score(y_val, preds, average='micro')))\n",
    "print(\"Validation LinearSVC Macro F1: {:.4f}\".format(f1_score(y_val, preds, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "multiple-jenny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 108 out of 108 | elapsed: 14.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                                       ('clf',\n",
       "                                        RandomForestClassifier(random_state=42))]),\n",
       "             param_grid={'clf__n_estimators': [100, 200, 300],\n",
       "                         'vec__min_df': [1, 5, 10],\n",
       "                         'vec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'vec__stop_words': ['english', None]},\n",
       "             scoring='f1_micro', verbose=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vec', CountVectorizer()), \n",
    "    ('clf', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "params = {'vec__ngram_range':[(1,1),(1,2)],\n",
    "          'vec__stop_words':['english', None], \n",
    "          #'vec__lowercase':[False, True],\n",
    "          'vec__min_df':[1, 5, 10],\n",
    "          'clf__n_estimators':[100, 200, 300]}\n",
    "clf = GridSearchCV(pipeline, params, scoring=\"f1_micro\", cv=3, verbose=1)\n",
    "clf.fit(X_txt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "current-hungarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomForest Micro F1: 0.7355\n",
      "Best RandomForest Parameters: {'clf__n_estimators': 300, 'vec__min_df': 5, 'vec__ngram_range': (1, 1), 'vec__stop_words': None}\n",
      "Validation RandomForest Micro F1: 0.7348\n",
      "Validation RandomForest Macro F1: 0.4699\n"
     ]
    }
   ],
   "source": [
    "print(\"Best RandomForest Micro F1: {:.4f}\".format(clf.best_score_))\n",
    "print(\"Best RandomForest Parameters:\", clf.best_params_)\n",
    "\n",
    "preds = clf.predict(X_txt_val)\n",
    "print(\"Validation RandomForest Micro F1: {:.4f}\".format(f1_score(y_val, preds, average='micro')))\n",
    "print(\"Validation RandomForest Macro F1: {:.4f}\".format(f1_score(y_val, preds, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "turkish-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "brave-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot.grid_search(clf.cv_results_, change='n_estimators', kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-massage",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
