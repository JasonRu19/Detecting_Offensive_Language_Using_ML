{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "possible-furniture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8473\n",
      "2119\n",
      "8473\n",
      "2119\n"
     ]
    }
   ],
   "source": [
    "#### SETUP ####\n",
    "\n",
    "import csv\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "# READ IN THE TRAINING DATA\n",
    "\n",
    "X_txt = []\n",
    "y = []\n",
    "with open('./train.tsv', encoding = 'utf-8') as in_file:\n",
    "    iCSV = csv.reader(in_file, delimiter='\\t')\n",
    "    for row in iCSV:\n",
    "        X_txt.append(row[1])\n",
    "        y.append(row[2])\n",
    "\n",
    "# SPLIT THE TRAINING DATA INTO TRAINING (80%) AND VALIDATION (20%) SUBSETS        \n",
    "\n",
    "X_txt_train, X_txt_val, y_train, y_val = train_test_split(X_txt, y, test_size=0.2, random_state=42)\n",
    "print(len(X_txt_train))\n",
    "print(len(X_txt_val))\n",
    "print(len(y_train))\n",
    "print(len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "atomic-glory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOT    7069\n",
       "TIN    3102\n",
       "UNT     421\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the breakdown of the 3 classes in our training data?\n",
    "\n",
    "import pandas\n",
    "pandas.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "powered-dinner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "[Parallel(n_jobs=1)]: Done 108 out of 108 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                                       ('clf', LinearSVC(random_state=42))]),\n",
       "             param_grid={'clf__C': [0.01, 0.1, 1.0], 'vec__min_df': [1, 5, 10],\n",
       "                         'vec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'vec__stop_words': ['english', None]},\n",
       "             scoring='f1_micro', verbose=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### TRAIN SOME BASELINE MODELS ####\n",
    "\n",
    "# LINEAR SVC\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vec', CountVectorizer()), \n",
    "    ('clf', LinearSVC(random_state=42))])\n",
    "\n",
    "params = {'vec__ngram_range':[(1,1),(1,2)],\n",
    "          'vec__stop_words':['english', None], \n",
    "          #'vec__lowercase':[False, True],\n",
    "          'vec__min_df':[1, 5, 10],\n",
    "          'clf__C':[0.01, 0.1, 1.]}\n",
    "clf = GridSearchCV(pipeline, params, scoring=\"f1_micro\", cv=3, verbose=1)\n",
    "clf.fit(X_txt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "human-error",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LinearSVC Micro F1: 0.7324\n",
      "Best LinearSVC Parameters: {'clf__C': 0.1, 'vec__min_df': 1, 'vec__ngram_range': (1, 1), 'vec__stop_words': 'english'}\n",
      "Validation LinearSVC Micro F1: 0.7268\n",
      "Validation LinearSVC Macro F1: 0.4487\n"
     ]
    }
   ],
   "source": [
    "print(\"Best LinearSVC Micro F1: {:.4f}\".format(clf.best_score_))\n",
    "print(\"Best LinearSVC Parameters:\", clf.best_params_)\n",
    "\n",
    "preds = clf.predict(X_txt_val)\n",
    "print(\"Validation LinearSVC Micro F1: {:.4f}\".format(f1_score(y_val, preds, average='micro')))\n",
    "print(\"Validation LinearSVC Macro F1: {:.4f}\".format(f1_score(y_val, preds, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cordless-knitting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 108 out of 108 | elapsed: 14.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                                       ('clf',\n",
       "                                        RandomForestClassifier(random_state=42))]),\n",
       "             param_grid={'clf__n_estimators': [100, 200, 300],\n",
       "                         'vec__min_df': [1, 5, 10],\n",
       "                         'vec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'vec__stop_words': ['english', None]},\n",
       "             scoring='f1_micro', verbose=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vec', CountVectorizer()), \n",
    "    ('clf', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "params = {'vec__ngram_range':[(1,1),(1,2)],\n",
    "          'vec__stop_words':['english', None], \n",
    "          #'vec__lowercase':[False, True],\n",
    "          'vec__min_df':[1, 5, 10],\n",
    "          'clf__n_estimators':[100, 200, 300]}\n",
    "clf = GridSearchCV(pipeline, params, scoring=\"f1_micro\", cv=3, verbose=1)\n",
    "clf.fit(X_txt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "painful-munich",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomForest Micro F1: 0.7355\n",
      "Best RandomForest Parameters: {'clf__n_estimators': 300, 'vec__min_df': 5, 'vec__ngram_range': (1, 1), 'vec__stop_words': None}\n",
      "Validation RandomForest Micro F1: 0.7348\n",
      "Validation RandomForest Macro F1: 0.4699\n"
     ]
    }
   ],
   "source": [
    "print(\"Best RandomForest Micro F1: {:.4f}\".format(clf.best_score_))\n",
    "print(\"Best RandomForest Parameters:\", clf.best_params_)\n",
    "\n",
    "preds = clf.predict(X_txt_val)\n",
    "print(\"Validation RandomForest Micro F1: {:.4f}\".format(f1_score(y_val, preds, average='micro')))\n",
    "print(\"Validation RandomForest Macro F1: {:.4f}\".format(f1_score(y_val, preds, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "wrong-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "significant-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot.grid_search(clf.cv_results_, change='n_estimators', kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "lesbian-blanket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@USER She should ask a few native Americans what their take on this is. UNT\n",
      "@USER @USER Go home youâ€™re drunk!!! @USER #MAGA #Trump2020 ðŸ‘ŠðŸ‡ºðŸ‡¸ðŸ‘Š URL TIN\n",
      "Amazon is investigating Chinese employees who are selling internal data to third-party sellers looking for an edge in the competitive marketplace. URL #Amazon #MAGA #KAG #CHINA #TCOT NOT\n",
      "@USER Someone should'veTaken\" this piece of shit to a volcano. ðŸ˜‚\" UNT\n",
      "@USER @USER Obama wanted liberals &amp; illegals to move into red states NOT\n",
      "@USER Liberals are all Kookoo !!! TIN\n",
      "@USER @USER Oh noes! Tough shit. UNT\n",
      "@USER was literally just talking about this lol all mass shootings like that have been set ups. itâ€™s propaganda used to divide us on major issues like gun control and terrorism TIN\n",
      "@USER Buy more icecream!!! NOT\n",
      "@USER Canada doesnâ€™t need another CUCK! We already have enough #LooneyLeft #Liberals f**king up our great country! #Qproofs #TrudeauMustGo TIN\n"
     ]
    }
   ],
   "source": [
    "# Examine some example tweets and their classes\n",
    "count = 0\n",
    "for a,b in zip(X_txt, y):\n",
    "    print(a,b)\n",
    "    count += 1\n",
    "    if count == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "elect-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add lexicon-based features\n",
    "\n",
    "class LexiconClassifier():\n",
    "    def __init__(self):\n",
    "        self.bad_words = set()\n",
    "        with open('bad-words.txt', encoding = 'utf-8') as iFile:\n",
    "            for row in iFile:\n",
    "                self.bad_words.add(row.strip())\n",
    "\n",
    "    def count_bad_words(self, sentence):\n",
    "        num_bad_words = 0\n",
    "        for word in sentence.lower().split():\n",
    "            # strip away anything not typical for a word \n",
    "            # (i.e., digits, most punctuation)\n",
    "            word = re.findall(r\"[A-Za-z'-]+\", word)\n",
    "            if len(word) > 0: \n",
    "                word = word[0]\n",
    "            else:\n",
    "                word = \"\"\n",
    "            if word in self.bad_words:\n",
    "                num_bad_words += 1\n",
    "        return num_bad_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "elegant-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "lc = LexiconClassifier()\n",
    "X_train_lexicon_features = [] # Initialize to an empty list. \n",
    "                              # This will be a list of lists\n",
    "X_val_lexicon_features = [] # Initialize to an empty list.\n",
    "                             # This will be a list of lists\n",
    "    \n",
    "for string in X_txt_val:\n",
    "    bad_count = lc.count_bad_words(string)  # Count bad words\n",
    "    message_length = len(string)  # Characters in tweet\n",
    "    words = string.split()  # Split into words\n",
    "    avg_word_length = 0\n",
    "    max_word_length = 0\n",
    "    for word in words:\n",
    "        avg_word_length += len(word)/len(words)  # Average word length\n",
    "        if len(word) > max_word_length:\n",
    "            max_word_length = len(word)  # Max word length\n",
    "    num_unique = len(set(string))  # Number of unique characters\n",
    "    prop_unique = num_unique/message_length  # Proportion of unique characters\n",
    "    num_letters = len(re.findall(r'[A-Za-z]',string))  # Number of letters\n",
    "    prop_letters = num_letters/message_length  # Proportion of letters\n",
    "    num_digits = len(re.findall(r'[0-9]',string))  # Number of digits\n",
    "    prop_digits = num_digits/message_length  # Proportion of digits\n",
    "    num_punct = len(re.findall(r'[:punct:]',string))  # Number of punctuation\n",
    "    prop_punct = num_punct/message_length  # Proportion of punctuation\n",
    "    num_space = len(re.findall(r'[ ]',string))  # Number of spaces\n",
    "    prop_space = num_space/message_length  # Proportion of spaces\n",
    "    num_atUSER = len(re.findall(r'@USER',string))  # Number of @USER\n",
    "    num_CAPS = len(re.findall(r'[A-Z]',string)) - 4*num_atUSER  \n",
    "        # Number of capital letters (removing @USER)\n",
    "    prop_CAPS = num_CAPS/message_length  # Proportion of capital letters\n",
    "    num_at = len(re.findall(r'[@]',string))  # Number of @\n",
    "    prop_at = num_at/message_length  # Proportion of @\n",
    "    num_exclam = len(re.findall(r'[!]',string))  # Number of !\n",
    "    prop_exclam = num_exclam/message_length  # Proportion of !\n",
    "    num_question = len(re.findall(r'[?]',string))  # Number of ?\n",
    "    prop_question = num_question/message_length  # Proportion of ?\n",
    "    num_exclam_seq = len(re.findall(r'[!]{2,}',string))  # Number of ! sequences 2+\n",
    "    num_quest_seq = len(re.findall(r'[?]{2,}',string))  # Number of ? sequences 2+\n",
    "    num_exclam_quest_seq = len(re.findall(r'([!]|[?])*(([!][?])|([?][!]))([!]|[?])*',string))  # Number of !/? sequences 2+\n",
    "    X_val_lexicon_features.append([bad_count, message_length, avg_word_length, max_word_length, \n",
    "                                   num_unique, prop_unique, num_letters, prop_letters, num_digits, \n",
    "                                   prop_digits, num_punct, prop_punct, num_space, prop_space, num_CAPS,\n",
    "                                   prop_CAPS, num_at, prop_at, num_exclam, prop_exclam, num_question,\n",
    "                                   prop_question, num_exclam_seq, num_quest_seq, num_exclam_quest_seq])\n",
    "\n",
    "for string in X_txt_train:\n",
    "    bad_count = lc.count_bad_words(string)  # Count bad words\n",
    "    message_length = len(string)  # Characters in tweet\n",
    "    words = string.split()  # Split into words\n",
    "    avg_word_length = 0\n",
    "    max_word_length = 0\n",
    "    for word in words:\n",
    "        avg_word_length += len(word)/len(words)  # Average word length\n",
    "        if len(word) > max_word_length:\n",
    "            max_word_length = len(word)  # Max word length\n",
    "    num_unique = len(set(string))  # Number of unique characters\n",
    "    prop_unique = num_unique/message_length  # Proportion of unique characters\n",
    "    num_letters = len(re.findall(r'[A-Za-z]',string))  # Number of letters\n",
    "    prop_letters = num_letters/message_length  # Proportion of letters\n",
    "    num_digits = len(re.findall(r'[0-9]',string))  # Number of digits\n",
    "    prop_digits = num_digits/message_length  # Proportion of digits\n",
    "    num_punct = len(re.findall(r'[:punct:]',string))  # Number of punctuation\n",
    "    prop_punct = num_punct/message_length  # Proportion of punctuation\n",
    "    num_space = len(re.findall(r'[ ]',string))  # Number of spaces\n",
    "    prop_space = num_space/message_length  # Proportion of spaces\n",
    "    num_atUSER = len(re.findall(r'@USER',string))  # Number of @USER\n",
    "    num_CAPS = len(re.findall(r'[A-Z]',string)) - 4*num_atUSER  \n",
    "        # Number of capital letters (removing @USER)\n",
    "    prop_CAPS = num_CAPS/message_length  # Proportion of capital letters\n",
    "    num_at = len(re.findall(r'[@]',string))  # Number of @\n",
    "    prop_at = num_at/message_length  # Proportion of @\n",
    "    num_exclam = len(re.findall(r'[!]',string))  # Number of !\n",
    "    prop_exclam = num_exclam/message_length  # Proportion of !\n",
    "    num_question = len(re.findall(r'[?]',string))  # Number of ?\n",
    "    prop_question = num_question/message_length  # Proportion of ?\n",
    "    num_exclam_seq = len(re.findall(r'[!]{2,}',string))  # Number of ! sequences 2+\n",
    "    num_quest_seq = len(re.findall(r'[?]{2,}',string))  # Number of ? sequences 2+\n",
    "    num_exclam_quest_seq = len(re.findall(r'([!]|[?])*(([!][?])|([?][!]))([!]|[?])*',string))  # Number of !/? sequences 2+\n",
    "    X_train_lexicon_features.append([bad_count, message_length, avg_word_length, max_word_length, \n",
    "                                     num_unique, prop_unique, num_letters, prop_letters, num_digits, \n",
    "                                     prop_digits, num_punct, prop_punct, num_space, prop_space, num_CAPS,\n",
    "                                     prop_CAPS, num_at, prop_at, num_exclam, prop_exclam, num_question,\n",
    "                                     prop_question, num_exclam_seq, num_quest_seq, num_exclam_quest_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "developed-endorsement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@USER @USER @USER You are grossly misinterpreting who is against this. People across all parties condemn this action. Look no further than Bill Davis and Brian Mulroney to see that even conservatives think this is a horrible decision.\n",
      "[0, 234, 5.1842105263157885, 15, 35, 0.14957264957264957, 191, 0.8162393162393162, 0, 0.0, 41, 0.1752136752136752, 37, 0.1581196581196581, 7, 0.029914529914529916, 3, 0.01282051282051282, 0, 0.0, 0, 0.0, 0, 0, 0]\n",
      "@USER Children  should be seen and not heard!!!\n",
      "[0, 47, 4.875, 8, 21, 0.44680851063829785, 35, 0.7446808510638298, 0, 0.0, 6, 0.1276595744680851, 8, 0.1702127659574468, 1, 0.02127659574468085, 1, 0.02127659574468085, 3, 0.06382978723404255, 0, 0.0, 1, 0, 0]\n",
      "@USER They've morphed into Antifa. Antifa gets better coverage and that all important Soros cash! ie: I'm so upset about you know racist stuff and Trump and children in cages and everything the like that, ya know?\"\"\n",
      "[1, 215, 4.837837837837838, 10, 38, 0.17674418604651163, 169, 0.786046511627907, 0, 0.0, 46, 0.21395348837209302, 36, 0.16744186046511628, 6, 0.027906976744186046, 1, 0.004651162790697674, 1, 0.004651162790697674, 1, 0.004651162790697674, 0, 0, 0]\n",
      "@USER WTH ??? What happened to gun control ???\n",
      "[3, 46, 4.222222222222222, 8, 23, 0.5, 31, 0.6739130434782609, 0, 0.0, 10, 0.21739130434782608, 8, 0.17391304347826086, 4, 0.08695652173913043, 1, 0.021739130434782608, 0, 0.0, 6, 0.13043478260869565, 0, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_txt_train[0])\n",
    "print(X_train_lexicon_features[0])\n",
    "print(X_txt_train[1])\n",
    "print(X_train_lexicon_features[1])\n",
    "print(X_txt_train[2])\n",
    "print(X_train_lexicon_features[2])\n",
    "print(X_txt_train[10])\n",
    "print(X_train_lexicon_features[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "dental-munich",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "vec = CountVectorizer(ngram_range=(1,1), min_df=1, stop_words='english')\n",
    "X_train = vec.fit_transform(X_txt_train) # This should be a matrix \n",
    "X_val = vec.transform(X_txt_val) # This should be a matrix\n",
    "\n",
    "X_train_lexicon_features = np.array(X_train_lexicon_features)\n",
    "X_val_lexicon_features = np.array(X_val_lexicon_features)\n",
    "X_train_w_lex = sp.hstack([X_train_lexicon_features, X_train])\n",
    "X_val_w_lex = sp.hstack([X_val_lexicon_features, X_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "nonprofit-mainstream",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(random_state=42),\n",
       "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0]},\n",
       "             scoring='f1_micro', verbose=1)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### TRAIN SOME MODELS WITH MORPHOLOGICAL FEATURES ADDED ####\n",
    "\n",
    "# LINEAR SVC\n",
    "\n",
    "params = {'C':[0.0001, 0.001, 0.01, 0.1, 1., 10., 100.]}\n",
    "\n",
    "lsvc = LinearSVC(random_state=42)\n",
    "grid = GridSearchCV(lsvc, params, scoring=\"f1_micro\", cv=5, verbose = 1)\n",
    "grid.fit(X_train_w_lex, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "abroad-treatment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LinearSVC Micro F1: 0.7133\n",
      "Best LinearSVC Parameters: {'C': 0.01}\n",
      "Validation LinearSVC Micro F1: 0.7324\n",
      "Validation LinearSVC Macro F1: 0.4385\n"
     ]
    }
   ],
   "source": [
    "print(\"Best LinearSVC Micro F1: {:.4f}\".format(grid.best_score_))\n",
    "print(\"Best LinearSVC Parameters:\", grid.best_params_)\n",
    "\n",
    "preds = grid.predict(X_val_w_lex)\n",
    "print(\"Validation LinearSVC Micro F1: {:.4f}\".format(f1_score(y_val, preds, average='micro')))\n",
    "print(\"Validation LinearSVC Macro F1: {:.4f}\".format(f1_score(y_val, preds, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "flying-jonathan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "vec = CountVectorizer(ngram_range=(1,1), min_df=5, stop_words=None)\n",
    "X_train = vec.fit_transform(X_txt_train) # This should be a matrix \n",
    "X_val = vec.transform(X_txt_val) # This should be a matrix\n",
    "\n",
    "X_train_lexicon_features = np.array(X_train_lexicon_features)\n",
    "X_val_lexicon_features = np.array(X_val_lexicon_features)\n",
    "X_train_w_lex = sp.hstack([X_train_lexicon_features, X_train])\n",
    "X_val_w_lex = sp.hstack([X_val_lexicon_features, X_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "downtown-boards",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'n_estimators': [100, 200, 300]}, scoring='f1_micro',\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "params = {'n_estimators':[100, 200, 300]}\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "grid = GridSearchCV(rfc, params, scoring=\"f1_micro\", cv=5, verbose = 1)\n",
    "grid.fit(X_train_w_lex, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "associate-witch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomForest Micro F1: 0.7221\n",
      "Best RandomForest Parameters: {'n_estimators': 300}\n",
      "Validation RandomForest Micro F1: 0.7263\n",
      "Validation RandomForest Macro F1: 0.4347\n"
     ]
    }
   ],
   "source": [
    "print(\"Best RandomForest Micro F1: {:.4f}\".format(grid.best_score_))\n",
    "print(\"Best RandomForest Parameters:\", grid.best_params_)\n",
    "\n",
    "preds = grid.predict(X_val_w_lex)\n",
    "print(\"Validation RandomForest Micro F1: {:.4f}\".format(f1_score(y_val, preds, average='micro')))\n",
    "print(\"Validation RandomForest Macro F1: {:.4f}\".format(f1_score(y_val, preds, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fifth-forwarding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@USER iâ€™m weak ðŸ˜‚ðŸ˜‚.. Shit must have been really painful ..\n",
      "57\n",
      "4.272727272727273\n",
      "7\n",
      "39\n",
      "0\n",
      "7\n",
      "10\n",
      "5\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Playing around with morphological features\n",
    "# Not part of workflow\n",
    "\n",
    "string = X_txt_val[2]\n",
    "print(string)\n",
    "print(len(string))\n",
    "words = string.split()\n",
    "avg_word_length = 0\n",
    "max_word_length = 0\n",
    "for word in words:\n",
    "    avg_word_length += len(word)/len(words)\n",
    "    if len(word) > max_word_length:\n",
    "        max_word_length = len(word)\n",
    "print(avg_word_length)\n",
    "print(max_word_length)\n",
    "print(len(re.findall(r'[A-Za-z]',string)))\n",
    "print(len(re.findall(r'[0-9]',string)))\n",
    "print(len(re.findall(r'[:punct:]',string)))\n",
    "print(len(re.findall(r'[ ]',string)))\n",
    "print(len(re.findall(r'[A-Z]',string)))\n",
    "print(len(re.findall(r'[@]',string)))\n",
    "print(len(re.findall(r'[!]',string)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "extra-pizza",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Playing around with morphological features\n",
    "# Not part of workflow\n",
    "string = \"So happy!?!? How about you???????????!\"\n",
    "num_exclam_seq = len(re.findall(r'[!]{2,}',string))  # Number of ! sequences 2+\n",
    "num_quest_seq = len(re.findall(r'[?]{2,}',string))  # Number of ? sequences 2+\n",
    "num_exclam_quest_seq = len(re.findall(r'([!]|[?])*(([!][?])|([?][!]))([!]|[?])*',string))  # Number of !/? sequences 2+\n",
    "print(num_exclam_seq)\n",
    "print(num_quest_seq)\n",
    "print(num_exclam_quest_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "processed-birth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"@poop#%&%\"\n",
    "lc.count_bad_words(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "junior-haven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed:   46.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vec', TfidfVectorizer()),\n",
       "                                       ('clf', LinearSVC(random_state=42))]),\n",
       "             param_grid={'clf__C': [0.01, 0.1, 1.0], 'vec__min_df': [1, 5, 10],\n",
       "                         'vec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'vec__stop_words': ['english', None]},\n",
       "             scoring='f1_micro', verbose=1)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### TRY TFIDF INSTEAD OF COUNT ####\n",
    "\n",
    "# LINEAR SVC\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vec', TfidfVectorizer()), \n",
    "    ('clf', LinearSVC(random_state=42))])\n",
    "\n",
    "params = {'vec__ngram_range':[(1,1),(1,2)],\n",
    "          'vec__stop_words':['english', None], \n",
    "          #'vec__lowercase':[False, True],\n",
    "          'vec__min_df':[1, 5, 10],\n",
    "          'clf__C':[0.01, 0.1, 1.]}\n",
    "clf = GridSearchCV(pipeline, params, scoring=\"f1_micro\", cv=5, verbose=1)\n",
    "clf.fit(X_txt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "instrumental-young",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LinearSVC Micro F1: 0.7329\n",
      "Best LinearSVC Parameters: {'clf__C': 1.0, 'vec__min_df': 1, 'vec__ngram_range': (1, 2), 'vec__stop_words': 'english'}\n",
      "Validation LinearSVC Micro F1: 0.7282\n",
      "Validation LinearSVC Macro F1: 0.4815\n"
     ]
    }
   ],
   "source": [
    "print(\"Best LinearSVC Micro F1: {:.4f}\".format(clf.best_score_))\n",
    "print(\"Best LinearSVC Parameters:\", clf.best_params_)\n",
    "\n",
    "preds = clf.predict(X_txt_val)\n",
    "print(\"Validation LinearSVC Micro F1: {:.4f}\".format(f1_score(y_val, preds, average='micro')))\n",
    "print(\"Validation LinearSVC Macro F1: {:.4f}\".format(f1_score(y_val, preds, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ready-asthma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed: 29.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vec', TfidfVectorizer()),\n",
       "                                       ('clf',\n",
       "                                        RandomForestClassifier(random_state=42))]),\n",
       "             param_grid={'clf__n_estimators': [100, 200, 300],\n",
       "                         'vec__min_df': [1, 5, 10],\n",
       "                         'vec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'vec__stop_words': ['english', None]},\n",
       "             scoring='f1_micro', verbose=1)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vec', TfidfVectorizer()), \n",
    "    ('clf', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "params = {'vec__ngram_range':[(1,1),(1,2)],\n",
    "          'vec__stop_words':['english', None], \n",
    "          #'vec__lowercase':[False, True],\n",
    "          'vec__min_df':[1, 5, 10],\n",
    "          'clf__n_estimators':[100, 200, 300]}\n",
    "clf = GridSearchCV(pipeline, params, scoring=\"f1_micro\", cv=5, verbose=1)\n",
    "clf.fit(X_txt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ordered-forum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomForest Micro F1: 0.7398\n",
      "Best RandomForest Parameters: {'clf__n_estimators': 200, 'vec__min_df': 5, 'vec__ngram_range': (1, 1), 'vec__stop_words': 'english'}\n",
      "Validation RandomForest Micro F1: 0.7381\n",
      "Validation RandomForest Macro F1: 0.4876\n"
     ]
    }
   ],
   "source": [
    "print(\"Best RandomForest Micro F1: {:.4f}\".format(clf.best_score_))\n",
    "print(\"Best RandomForest Parameters:\", clf.best_params_)\n",
    "\n",
    "preds = clf.predict(X_txt_val)\n",
    "print(\"Validation RandomForest Micro F1: {:.4f}\".format(f1_score(y_val, preds, average='micro')))\n",
    "print(\"Validation RandomForest Macro F1: {:.4f}\".format(f1_score(y_val, preds, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "sophisticated-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "vec = TfidfVectorizer(ngram_range=(1,1), min_df=1, stop_words='english')\n",
    "X_train = vec.fit_transform(X_txt_train) # This should be a matrix \n",
    "X_val = vec.transform(X_txt_val) # This should be a matrix\n",
    "\n",
    "X_train_lexicon_features = np.array(X_train_lexicon_features)\n",
    "X_val_lexicon_features = np.array(X_val_lexicon_features)\n",
    "X_train_w_lex = sp.hstack([X_train_lexicon_features, X_train])\n",
    "X_val_w_lex = sp.hstack([X_val_lexicon_features, X_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "consecutive-protocol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(random_state=42),\n",
       "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0]},\n",
       "             scoring='f1_micro', verbose=1)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### TFIDF WITH MORPHOLOGICAL FEATURES ADDED ####\n",
    "\n",
    "# LINEAR SVC\n",
    "\n",
    "params = {'C':[0.0001, 0.001, 0.01, 0.1, 1., 10., 100.]}\n",
    "\n",
    "lsvc = LinearSVC(random_state=42)\n",
    "grid = GridSearchCV(lsvc, params, scoring=\"f1_micro\", cv=5, verbose = 1)\n",
    "grid.fit(X_train_w_lex, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "liked-constant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LinearSVC Micro F1: 0.6812\n",
      "Best LinearSVC Parameters: {'C': 0.01}\n",
      "Validation LinearSVC Micro F1: 0.6947\n",
      "Validation LinearSVC Macro F1: 0.3818\n"
     ]
    }
   ],
   "source": [
    "print(\"Best LinearSVC Micro F1: {:.4f}\".format(grid.best_score_))\n",
    "print(\"Best LinearSVC Parameters:\", grid.best_params_)\n",
    "\n",
    "preds = grid.predict(X_val_w_lex)\n",
    "print(\"Validation LinearSVC Micro F1: {:.4f}\".format(f1_score(y_val, preds, average='micro')))\n",
    "print(\"Validation LinearSVC Macro F1: {:.4f}\".format(f1_score(y_val, preds, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "worldwide-toyota",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "vec = TfidfVectorizer(ngram_range=(1,1), min_df=5, stop_words='english')\n",
    "X_train = vec.fit_transform(X_txt_train) # This should be a matrix \n",
    "X_val = vec.transform(X_txt_val) # This should be a matrix\n",
    "\n",
    "X_train_lexicon_features = np.array(X_train_lexicon_features)\n",
    "X_val_lexicon_features = np.array(X_val_lexicon_features)\n",
    "X_train_w_lex = sp.hstack([X_train_lexicon_features, X_train])\n",
    "X_val_w_lex = sp.hstack([X_val_lexicon_features, X_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "canadian-notebook",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'n_estimators': [100, 200, 300]}, scoring='f1_micro',\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "params = {'n_estimators':[100, 200, 300]}\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "grid = GridSearchCV(rfc, params, scoring=\"f1_micro\", cv=5, verbose = 1)\n",
    "grid.fit(X_train_w_lex, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "digital-patrol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomForest Micro F1: 0.7282\n",
      "Best RandomForest Parameters: {'n_estimators': 200}\n",
      "Validation RandomForest Micro F1: 0.7272\n",
      "Validation RandomForest Macro F1: 0.4335\n"
     ]
    }
   ],
   "source": [
    "print(\"Best RandomForest Micro F1: {:.4f}\".format(grid.best_score_))\n",
    "print(\"Best RandomForest Parameters:\", grid.best_params_)\n",
    "\n",
    "preds = grid.predict(X_val_w_lex)\n",
    "print(\"Validation RandomForest Micro F1: {:.4f}\".format(f1_score(y_val, preds, average='micro')))\n",
    "print(\"Validation RandomForest Macro F1: {:.4f}\".format(f1_score(y_val, preds, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "violent-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTI-LAYER PERCEPTRON (NEURAL NETWORK)\n",
    "\n",
    "## THIS CODE DOES NOT WORK\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipeline = Pipeline([\n",
    "#    ('vec', TfidfVectorizer()), \n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', MLPClassifier(solver='lbfgs', alpha=1e-5, random_state=42))])\n",
    "\n",
    "params = {#'vec__ngram_range':[(1,1),(1,2)],\n",
    "          #'vec__stop_words':['english', None], \n",
    "          #'vec__lowercase':[False, True],\n",
    "          #'vec__min_df':[1, 5, 10],\n",
    "          'clf__hidden_layer_sizes':[(5,2)]}\n",
    "clf = GridSearchCV(pipeline, params, scoring=\"f1_micro\", cv=3, verbose=1)\n",
    "#clf.fit(X_txt_train, y_train)\n",
    "#clf.fit(X_train_lexicon_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "rubber-thunder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(15, 5), max_iter=300, random_state=42)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MULTI-LAYER PERCEPTRON (NEURAL NETWORK)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "mlp = MLPClassifier(random_state=42, hidden_layer_sizes=(15,5), max_iter=300)\n",
    "mlp.fit(X_train_w_lex, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "hired-walter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MLP Micro F1: 0.6583\n",
      "Validation MLP Macro F1: 0.4745\n"
     ]
    }
   ],
   "source": [
    "preds = mlp.predict(X_val_w_lex)\n",
    "print(\"Validation MLP Micro F1: {:.4f}\".format(f1_score(y_val, preds, average='micro')))\n",
    "print(\"Validation MLP Macro F1: {:.4f}\".format(f1_score(y_val, preds, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "periodic-saver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 352, in fit\n",
      "    self._check_params(X, y)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 523, in _check_params\n",
      "    raise ValueError(\"k should be >=0, <= n_features = %d; got %r. \"\n",
      "ValueError: k should be >=0, <= n_features = 947; got 1000. Use k='all' to return all features.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 352, in fit\n",
      "    self._check_params(X, y)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 523, in _check_params\n",
      "    raise ValueError(\"k should be >=0, <= n_features = %d; got %r. \"\n",
      "ValueError: k should be >=0, <= n_features = 908; got 1000. Use k='all' to return all features.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 352, in fit\n",
      "    self._check_params(X, y)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 523, in _check_params\n",
      "    raise ValueError(\"k should be >=0, <= n_features = %d; got %r. \"\n",
      "ValueError: k should be >=0, <= n_features = 954; got 1000. Use k='all' to return all features.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 352, in fit\n",
      "    self._check_params(X, y)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 523, in _check_params\n",
      "    raise ValueError(\"k should be >=0, <= n_features = %d; got %r. \"\n",
      "ValueError: k should be >=0, <= n_features = 947; got 1000. Use k='all' to return all features.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 352, in fit\n",
      "    self._check_params(X, y)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 523, in _check_params\n",
      "    raise ValueError(\"k should be >=0, <= n_features = %d; got %r. \"\n",
      "ValueError: k should be >=0, <= n_features = 908; got 1000. Use k='all' to return all features.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 352, in fit\n",
      "    self._check_params(X, y)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 523, in _check_params\n",
      "    raise ValueError(\"k should be >=0, <= n_features = %d; got %r. \"\n",
      "ValueError: k should be >=0, <= n_features = 954; got 1000. Use k='all' to return all features.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 352, in fit\n",
      "    self._check_params(X, y)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 523, in _check_params\n",
      "    raise ValueError(\"k should be >=0, <= n_features = %d; got %r. \"\n",
      "ValueError: k should be >=0, <= n_features = 947; got 1000. Use k='all' to return all features.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 352, in fit\n",
      "    self._check_params(X, y)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 523, in _check_params\n",
      "    raise ValueError(\"k should be >=0, <= n_features = %d; got %r. \"\n",
      "ValueError: k should be >=0, <= n_features = 908; got 1000. Use k='all' to return all features.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 330, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 292, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 693, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 352, in fit\n",
      "    self._check_params(X, y)\n",
      "  File \"/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py\", line 523, in _check_params\n",
      "    raise ValueError(\"k should be >=0, <= n_features = %d; got %r. \"\n",
      "ValueError: k should be >=0, <= n_features = 954; got 1000. Use k='all' to return all features.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done 432 out of 432 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('vec', TfidfVectorizer()),\n",
       "                                       ('skbest',\n",
       "                                        SelectKBest(score_func=<function chi2 at 0x7fb9944f35e0>)),\n",
       "                                       ('clf', LinearSVC(random_state=42))]),\n",
       "             param_grid={'clf__C': [0.01, 0.1, 1.0],\n",
       "                         'skbest__k': [10, 100, 1000, 'all'],\n",
       "                         'vec__min_df': [1, 5, 10],\n",
       "                         'vec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'vec__stop_words': ['english', None]},\n",
       "             scoring='f1_micro', verbose=1)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### EXPLORE USING SelectKBest ####\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# LINEAR SVC\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vec', TfidfVectorizer()), \n",
    "    ('skbest', SelectKBest(chi2)),\n",
    "    ('clf', LinearSVC(random_state=42))])\n",
    "\n",
    "params = {'vec__ngram_range':[(1,1),(1,2)],\n",
    "          'vec__stop_words':['english', None], \n",
    "          #'vec__lowercase':[False, True],\n",
    "          'vec__min_df':[1, 5, 10],\n",
    "          'skbest__k':[10,100,1000,'all'],\n",
    "          'clf__C':[0.01, 0.1, 1.]}\n",
    "clf = GridSearchCV(pipeline, params, scoring=\"f1_micro\", cv=3, verbose=1)\n",
    "clf.fit(X_txt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "legitimate-bibliography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LinearSVC Micro F1: 0.7354\n",
      "Best LinearSVC Parameters: {'clf__C': 1.0, 'skbest__k': 1000, 'vec__min_df': 1, 'vec__ngram_range': (1, 1), 'vec__stop_words': 'english'}\n",
      "Validation LinearSVC Micro F1: 0.7253\n",
      "Validation LinearSVC Macro F1: 0.4443\n"
     ]
    }
   ],
   "source": [
    "print(\"Best LinearSVC Micro F1: {:.4f}\".format(clf.best_score_))\n",
    "print(\"Best LinearSVC Parameters:\", clf.best_params_)\n",
    "\n",
    "preds = clf.predict(X_txt_val)\n",
    "print(\"Validation LinearSVC Micro F1: {:.4f}\".format(f1_score(y_val, preds, average='micro')))\n",
    "print(\"Validation LinearSVC Macro F1: {:.4f}\".format(f1_score(y_val, preds, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "statistical-rebate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:  2.5min finished\n",
      "/Users/Ben/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('skbest',\n",
       "                                        SelectKBest(score_func=<function chi2 at 0x7fb9944f35e0>)),\n",
       "                                       ('clf',\n",
       "                                        LinearSVC(max_iter=2000,\n",
       "                                                  random_state=42))]),\n",
       "             param_grid={'clf__C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],\n",
       "                         'skbest__k': [10, 100, 1000, 'all']},\n",
       "             scoring='f1_micro', verbose=1)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LINEAR SVC\n",
    "\n",
    "import scipy.sparse as sp\n",
    "\n",
    "vec = TfidfVectorizer(ngram_range=(1,1), min_df=1, stop_words='english')\n",
    "X_train = vec.fit_transform(X_txt_train) # This should be a matrix \n",
    "X_val = vec.transform(X_txt_val) # This should be a matrix\n",
    "\n",
    "X_train_lexicon_features = np.array(X_train_lexicon_features)\n",
    "X_val_lexicon_features = np.array(X_val_lexicon_features)\n",
    "X_train_w_lex = sp.hstack([X_train_lexicon_features, X_train])\n",
    "X_val_w_lex = sp.hstack([X_val_lexicon_features, X_val])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('skbest', SelectKBest(chi2)),\n",
    "    ('clf', LinearSVC(random_state=42, max_iter=2000))])\n",
    "\n",
    "params = {'skbest__k':[10,100,1000,'all'],\n",
    "          'clf__C':[0.001, 0.01, 0.1, 1., 10., 100.]}\n",
    "clf = GridSearchCV(pipeline, params, scoring=\"f1_micro\", cv=3, verbose=1)\n",
    "clf.fit(X_train_w_lex, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "cathedral-candidate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LinearSVC Micro F1: 0.6941\n",
      "Best LinearSVC Parameters: {'clf__C': 0.1, 'skbest__k': 'all'}\n",
      "Validation LinearSVC Micro F1: 0.7244\n",
      "Validation LinearSVC Macro F1: 0.4357\n"
     ]
    }
   ],
   "source": [
    "print(\"Best LinearSVC Micro F1: {:.4f}\".format(clf.best_score_))\n",
    "print(\"Best LinearSVC Parameters:\", clf.best_params_)\n",
    "\n",
    "preds = clf.predict(X_val_w_lex)\n",
    "print(\"Validation LinearSVC Micro F1: {:.4f}\".format(f1_score(y_val, preds, average='micro')))\n",
    "print(\"Validation LinearSVC Macro F1: {:.4f}\".format(f1_score(y_val, preds, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-malpractice",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
